ğŸ¬ IMDB AI Assistant
Enterprise-Grade RAG Movie Intelligence Platform

An AI-powered movie intelligence system built using Retrieval-Augmented Generation (RAG) architecture.
This application enables structured, contextual, and reliable movie search using semantic embeddings and a local LLM.

Designed with clean architecture principles, modular services, and a Netflix-style UI.

ğŸš€ Features
ğŸ§  AI-Powered Movie Search

Semantic search using vector embeddings

Structured LLM responses

Context-aware retrieval (RAG pipeline)

Deterministic formatted output

ğŸ—‚ Enterprise Architecture

Clean separation of concerns

Service-based modular design

Config-driven architecture

Cached vector store

Scalable folder structure

ğŸ¨ Professional UI

Netflix-inspired dark theme

Styled movie cards

Clean chat interface

Responsive layout

ğŸ“Š Analytics Dashboard

Genre distribution

Rating distribution

Movies per year trends

Key dataset metrics

ğŸ— Architecture Overview
User Input
   â†“
Streamlit UI (app.py)
   â†“
RAG Service
   â”œâ”€â”€ Vector Store (ChromaDB)
   â”œâ”€â”€ Retriever (Top-K search)
   â””â”€â”€ LLM Chain (Ollama + Prompt Template)
   â†“
Structured Movie Response
   â†“
Styled UI Rendering


This project follows a proper RAG architecture pattern:

Embeddings: mxbai-embed-large

Vector Store: Chroma

LLM: gemma3:1b (Ollama)

Framework: LangChain

UI: Streamlit

ğŸ“ Project Structure
imdb_ai_app/
â”‚
â”œâ”€â”€ app.py                 # Streamlit UI layer
â”œâ”€â”€ config.py              # Central configuration
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ imdb_top_1000.csv
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ llm_service.py
â”‚
â””â”€â”€ chroma_db/             # Persistent vector database

Layer Responsibilities
Layer	Responsibility
UI (app.py)	Rendering & interaction
rag_service	Orchestrates retrieval + generation
vector_store	Embeddings + persistence
llm_service	Prompt + LLM logic
config.py	Centralized configuration
ğŸ§  RAG Implementation Details
1ï¸âƒ£ Vector Store

Uses ChromaDB for persistence

Documents built from IMDB dataset

Embeddings generated using Ollama

2ï¸âƒ£ Retrieval

Top-K semantic search

Context filtering before generation

3ï¸âƒ£ Generation

Structured prompt template

Strict formatting enforcement

Context-bound answers only

ğŸ’» Tech Stack

Python

Streamlit

LangChain

Ollama

ChromaDB

Pandas

âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/yourusername/imdb-ai-assistant.git
cd imdb-ai-assistant

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Install Ollama & Pull Models

Install Ollama from:

https://ollama.com/

Then pull required models:

ollama pull gemma3:1b
ollama pull mxbai-embed-large

4ï¸âƒ£ Run the Application
streamlit run app.py

ğŸ“Š Dataset

Source: IMDB Top 1000 Movies Dataset
Columns include:

Title

Release Year

Genre

Director

Stars

IMDB Rating

Overview

Votes

Gross Revenue

ğŸ”¥ Key Engineering Highlights

No runtime re-embedding on every rerun

Persistent vector DB

Service-layer abstraction

Config-driven environment

Strict prompt formatting

Scalable design for multi-dataset expansion

Production-ready modular structure

ğŸš€ Future Enhancements

ğŸ TMDB Poster Integration

âš¡ Streaming LLM Responses

ğŸ¯ Recommendation Engine

ğŸ§© Multi-dataset Support

ğŸ³ Dockerization

â˜ Cloud Deployment

ğŸ“ˆ Monitoring & Logging

ğŸ† Why This Project Matters

This project demonstrates:

Practical implementation of RAG

Clean AI system architecture

Modular design principles

Scalable ML system design

UI/UX integration with LLM systems

Production-ready code structure

It is not a prototype â€” it follows real-world AI system design patterns.

ğŸ“„ License

MIT License
